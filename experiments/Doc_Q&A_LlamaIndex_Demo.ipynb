{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e95ebf-7cbc-41bf-8ed0-6fc039d08d7a",
   "metadata": {},
   "source": [
    "# Doc Q&A Demo\n",
    "This notebook contains an example of Doc Q&A, where a user can upload a document and ask questions about it. The pipeline will take the following steps:\n",
    "1. Parse the document in text format\n",
    "2. Chunk the text\n",
    "3. Embed each chunk\n",
    "4. Index chunks and store in an in-memory vector database to allow semantic search\n",
    "\n",
    "The example is built with the llama-index library.\n",
    "\n",
    "References: https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/q_and_a/#qa-patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c957419b-0d77-4939-86bb-9529c3a8b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.text_overlap import find_overlap, find_overlap_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e10a0da-cc7c-4458-b5ed-6deef8062514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e816ed-2167-442f-b0b3-100e540ce889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_Settings(_llm=MockLLM(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fd5a5f99a10>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7fd65557e0c0>, completion_to_prompt=<function default_completion_to_prompt at 0x7fd6553e9760>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, max_tokens=None), _embed_model=MockEmbedding(model_name='unknown', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fd5a5f99a10>, embed_dim=1), _callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fd5a5f99a10>, _tokenizer=None, _node_parser=None, _prompt_helper=None, _transformations=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.llm = None\n",
    "Settings.embed_model = None\n",
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed641e7-1815-4340-9960-6bc65b6f02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777e7f3-0b52-4e7e-ba97-a56e03ea9a98",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa4eda0-d07a-4178-b9cd-82cb7c94df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all text document from the folder docs/\n",
    "documents = SimpleDirectoryReader(\"docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88659651-ee51-48a8-ac40-64d725e6d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "123f2354-dc8f-4415-8585-c0292c7a28e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.schema.Document'>\n",
      "dict_keys(['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator', 'class_name'])\n",
      "{'file_path': '/home/experiments/docs/state_of_the_union.txt', 'file_name': 'state_of_the_union.txt', 'file_type': 'text/plain', 'file_size': 39027, 'creation_date': '2023-05-10', 'last_modified_date': '2023-05-10'}\n"
     ]
    }
   ],
   "source": [
    "doc_0 = documents[0]\n",
    "print(type(doc_0))\n",
    "print(doc_0.dict().keys())\n",
    "print(doc_0.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8783525f-b10b-4c59-9bca-02e04781f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Config', '__abstractmethods__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_calculate_keys', '_compat_fields', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', 'as_related_node_info', 'child_nodes', 'class_name', 'construct', 'copy', 'dict', 'doc_id', 'embedding', 'end_char_idx', 'example', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'extra_info', 'from_dict', 'from_embedchain_format', 'from_haystack_format', 'from_json', 'from_langchain_format', 'from_orm', 'from_semantic_kernel_format', 'get_content', 'get_doc_id', 'get_embedding', 'get_metadata_str', 'get_node_info', 'get_text', 'get_type', 'hash', 'id_', 'json', 'metadata', 'metadata_seperator', 'metadata_template', 'next_node', 'node_id', 'node_info', 'parent_node', 'parse_file', 'parse_obj', 'parse_raw', 'prev_node', 'ref_doc_id', 'relationships', 'schema', 'schema_json', 'set_content', 'source_node', 'start_char_idx', 'text', 'text_template', 'to_dict', 'to_embedchain_format', 'to_haystack_format', 'to_json', 'to_langchain_format', 'to_semantic_kernel_format', 'to_vectorflow', 'update_forward_refs', 'validate']\n"
     ]
    }
   ],
   "source": [
    "# Print all properties and methods of a Document object\n",
    "print(dir(doc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d13fec-d3ab-49c3-bb32-b3068b8c6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Every\n"
     ]
    }
   ],
   "source": [
    "# View the first few lines of object doc_0\n",
    "print(doc_0.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d039d5-2e3f-402b-a547-24f14b87631b",
   "metadata": {},
   "source": [
    "# Index the documents\n",
    "The basic LlamaIndex example uses the one-line command `VectorStoreIndex.from_documents` to index/chunk/embed all the documents. It wouldn't work in my case though, as I would keep running into a `RateLimitError`. The error message pointed toward my OpenAI account. After some [digging](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/embeddings/utils.py#L31), I could confirm that LlamaIndex's default embedding model is OpenAI's; which would fail in my case as my account is empty. Also, since I want to use open-source solutions in that example, I need to use a different approach.\n",
    "\n",
    "The solution is to define explicitly the embedding model that I want to use. And to do that in LlamaIndex, we need to [use the ingestion pipeline](https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/#using-the-ingestion-pipeline-to-create-nodes). LlamaIndex even has a nice [tutorial](https://docs.llamaindex.ai/en/stable/examples/low_level/oss_ingestion_retrieval/) and how to set it up with the sentence embedding model from HuggingFace's transformer library, which is exactly what I was hoping to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032ca4f-5075-42dd-b612-980c43f077a9",
   "metadata": {},
   "source": [
    "## Split the document\n",
    "\n",
    "In this example, we're using `SentenceSplitter` which is a pretty basic type of text splitter, only making sure to not break sentences (see [documentation](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_splitter/)). \n",
    "\n",
    "It would be interesting to play with more complex splitter like `SemanticSplitter` which attempts to build chunks containing text that is semantically related ([doc](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/semantic_splitter/)). That imo makes a lot of sense and is an idea I was playing with in the past. It'd be interesting to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad14f36e-b31f-4bac-a386-791eca855301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mSentenceSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseparator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunk_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunk_overlap\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparagraph_separator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n\\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunking_tokenizer_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msecondary_chunking_regex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[^,.;。？！]+[,.;。？！]?'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallback_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude_metadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude_prev_next_rel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mid_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Parse text with a preference for complete sentences.\n",
       "\n",
       "In general, this class tries to keep sentences and paragraphs together. Therefore\n",
       "compared to the original TokenTextSplitter, there are less likely to be\n",
       "hanging sentences or parts of sentences at the end of the node chunk.\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initialize with parameters.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.11/site-packages/llama_index/core/node_parser/text/sentence.py\n",
       "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SentenceSplitter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51c736e2-d3be-40d7-8945-8366598564a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128\n",
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=min(200, int(chunk_size*0.5)),\n",
    "    # separator=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b68e1c5-a852-49fc-b76e-e3f563cfcaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "# maintain relationship with source doc index, to help inject doc metadata in next step\n",
    "doc_idxs = [] # keep track of what document each chunk comes from\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04d4efbd-0b93-4647-8ce0-bfc7afae00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_idxs), doc_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7027ef0-5732-4326-9e64-d4ee53aa4e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All documents were split into a total of 129 chunks.\n",
      "The total length of all chunks is 68840 compared to 38539 for the original document.\n"
     ]
    }
   ],
   "source": [
    "print(f\"All documents were split into a total of {len(text_chunks)} chunks.\")\n",
    "print(f\"The total length of all chunks is {sum([len(ch) for ch in text_chunks])}\" + \n",
    "      f\" compared to {len(doc_0.text)} for the original document.\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c75cc993-cf05-4317-9f6f-dc0193ea5ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(290, 200),\n",
       " (292, 293),\n",
       " (292, 295),\n",
       " (283, 295),\n",
       " (263, 286),\n",
       " (228, 340),\n",
       " (231, 299),\n",
       " (229, 372),\n",
       " (287, 305),\n",
       " (285, 343)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out by how much all chunks overlap\n",
    "overlaps = find_overlap_chunks(text_chunks)\n",
    "overlaps[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c10ae2fa-518c-42b1-a499-6a8863eac0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0, -1), 58}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for potential problems:\n",
    "errors = [{idx, overlap} for idx, overlap in enumerate(overlaps) if overlap[0] == 0]\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca41979c-26ff-45da-b8c9-0788bd8e755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the overlap for one example\n",
    "idx = 4\n",
    "over = overlaps[idx]\n",
    "len_over = over[0]\n",
    "idx_over = over[1]\n",
    "text_0 = text_chunks[idx]\n",
    "text_1 = text_chunks[idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bba7cd67-658d-45e6-8b6f-e3d451200564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
      "\n",
      "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
      "\n",
      "They keep moving.\n",
      "--------------------------------------------------------------------------------\n",
      "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
      "\n",
      "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
      "\n",
      "They keep moving.\n"
     ]
    }
   ],
   "source": [
    "# print the overlap\n",
    "print(text_0[idx_over:])\n",
    "print(\"----\"*20)\n",
    "print(text_1[:len_over])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4d20b-91b3-406f-8bbc-00876cd9a957",
   "metadata": {},
   "source": [
    "## Construct a Node for each text chunk\n",
    "\n",
    "Nodes are a concept specific to LlamaIndex (afaik). They are chunks of documents (text, image, audio,...) augmented with metadata and relational information (for more, see the [LlamaIndex documentation](https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b77a437-0c97-4567-b62d-0fde57fced5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTextNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mid_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0membedding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextra_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexcluded_embed_metadata_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexcluded_llm_metadata_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrelationships\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNodeRelationship\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRelatedNodeInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRelatedNodeInfo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstart_char_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mend_char_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_template\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{metadata_str}\\n\\n{content}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata_template\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{key}: {value}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata_seperator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Base node Object.\n",
       "\n",
       "Generic abstract interface for retrievable nodes\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.11/site-packages/llama_index/core/schema.py\n",
       "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[0;31mSubclasses:\u001b[0m     ImageNode, IndexNode, Document"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TextNode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38f606ec-d362-4b49-b2e8-7cdeea2c834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for idx, _text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(text=_text_chunk) # create a node\n",
    "    src_doc = documents[doc_idxs[idx]] # save a copy of the original document that chunk was taken from\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "364ffc53-98f9-4ee9-9fa0-de2607401046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "['Config', '__abstractmethods__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', 'as_related_node_info', 'child_nodes', 'class_name', 'construct', 'copy', 'dict', 'embedding', 'end_char_idx', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'extra_info', 'from_dict', 'from_json', 'from_orm', 'get_content', 'get_embedding', 'get_metadata_str', 'get_node_info', 'get_text', 'get_type', 'hash', 'id_', 'json', 'metadata', 'metadata_seperator', 'metadata_template', 'next_node', 'node_id', 'node_info', 'parent_node', 'parse_file', 'parse_obj', 'parse_raw', 'prev_node', 'ref_doc_id', 'relationships', 'schema', 'schema_json', 'set_content', 'source_node', 'start_char_idx', 'text', 'text_template', 'to_dict', 'to_json', 'update_forward_refs', 'validate']\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))\n",
    "print(dir(nodes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e56f43-c8bb-4c2f-b03d-dd865954bf6f",
   "metadata": {},
   "source": [
    "## Embed each Node\n",
    "\n",
    "Embeddings of each Node are added to the Node in the form of a property (`embedding`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb499f27-2184-4d96-aa4a-9918f3ebb850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed_model_name = \"BAAI/bge-small-en-v1.5\" # https://huggingface.co/BAAI/bge-small-en-v1.5\n",
    "# embed_model_name = \"BAAI/bge-base-en-v1.5\" # larger dimension of the embedding space (768 vs 384)\n",
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\" # https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13f2d02a-c3ff-406f-a66d-1577cfb84523",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "576404de-4484-48df-81f5-979fcca6a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(node.get_content(metadata_mode=\"all\"))\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc688475-da6b-4851-8e62-623f2467701c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d218e05-5f4a-4905-ae7d-9e31d81722fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7254fb2a-c241-46b1-bbb9-28ceef6fc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_add_nodes_to_index', '_aget_node_with_embedding', '_async_add_nodes_to_index', '_build_index_from_nodes', '_callback_manager', '_delete_node', '_docstore', '_embed_model', '_get_node_with_embedding', '_graph_store', '_index_struct', '_insert', '_insert_batch_size', '_is_protocol', '_object_map', '_service_context', '_show_progress', '_storage_context', '_store_nodes_override', '_transformations', '_use_async', '_vector_store', 'as_chat_engine', 'as_query_engine', 'as_retriever', 'build_index_from_nodes', 'delete', 'delete_nodes', 'delete_ref_doc', 'docstore', 'from_documents', 'from_vector_store', 'index_id', 'index_struct', 'index_struct_cls', 'insert', 'insert_nodes', 'ref_doc_info', 'refresh', 'refresh_ref_docs', 'service_context', 'set_index_id', 'storage_context', 'summary', 'update', 'update_ref_doc', 'vector_store']\n"
     ]
    }
   ],
   "source": [
    "print(dir(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "832c8fa0-3f03-482e-8f7f-5f0387963c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 129)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index.docstore.get_all_document_hashes()), len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288bd242-a1ce-4df1-892c-afa8efc104c5",
   "metadata": {},
   "source": [
    "# Retrieve a document chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c400f4e6-de2d-4ece-b13c-c7993d7bc26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87080613-f9c3-476d-8ca6-f3c43d39cb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='sentence-transformers/all-MiniLM-L6-v2', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fd5a5f99a10>, max_length=256, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever._embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d43650dc-fb56-4c36-bf4b-327d4a6f11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"By how much will the deficit be down by the end of this year?\"\n",
    "documents_retrieved = retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07686728-ad04-4ebd-8e78-16375a619006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #1:\n",
      "Document #2:\n",
      "Document #3:\n",
      "Document #4:\n",
      "Good answer\n",
      "Document #5:\n"
     ]
    }
   ],
   "source": [
    "for rank, doc in enumerate(documents_retrieved):\n",
    "    print(f\"Document #{rank+1}:\")\n",
    "    #print(doc)\n",
    "    if \"the deficit will be down to less than half what it was before I took office\" in doc.get_content():\n",
    "        print(\"Good answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f0453-9f93-407c-9ba6-bf7e4097cabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
